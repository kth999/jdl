{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.2. 전이 학습"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "개와 고양이 이미지셋 주소\n",
    "https://www.kaggle.com/competitions/dogs-vs-cats/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Metalhead, Images\n",
    "using StatsBase: sample, shuffle\n",
    "import Flux, NNlib\n",
    "import Zygote, Optimisers, Functors\n",
    "using Formatting: printfmtln\n",
    "using Random: MersenneTwister"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_image_sampler (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_image_sampler(path, rng)\n",
    "    if isempty(readdir(path))\n",
    "        error(\"Empty train folder\")\n",
    "    end\n",
    "    files = joinpath.(path, readdir(path))    \n",
    "    dogs = filter(x -> occursin(\"dog\", x), files)\n",
    "    cats = filter(x -> occursin(\"cat\", x), files) \n",
    "\n",
    "    function image_sampler(n = 10, size = (224, 224))\n",
    "        @assert iseven(n)\n",
    "        dogs_ = sample(rng, dogs, Int(n/2))\n",
    "        cats_ = sample(rng, cats, Int(n/2))\n",
    "        imgs_paths = shuffle(rng, vcat(dogs_, cats_))\n",
    "\n",
    "        imgs = Images.load.(imgs_paths)\n",
    "        imgs = map(img -> Images.imresize(img, size...), imgs)\n",
    "        \n",
    "        imgs = map(imgs) do img # [CHW] -> [WHC]\n",
    "            permutedims(Images.channelview(img), (3,2,1))\n",
    "        end\n",
    "        imgs = cat(imgs..., dims = 4) # [WHC] => WHCN\n",
    "        imgs = Float32.(imgs)\n",
    "\n",
    "        labels = map(x -> occursin(\"dog\", x) ? 1 : 0, imgs_paths)\n",
    "        labels = Flux.onehotbatch(labels, [0,1])\n",
    "\n",
    "        imgs, labels\n",
    "    end\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습, 테스트 함수 (16장과 동일)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "init (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train(loader, model, loss_fn, optimizer)\n",
    "    num_batches = length(loader)\n",
    "    Flux.testmode!(model, false)\n",
    "    for (batch, (X, y)) in enumerate(loader)\n",
    "        X, y = Flux.gpu(X), Flux.gpu(y)\n",
    "        grad = Zygote.gradient(m -> loss_fn(m, X, y), model)[1]\n",
    "        optimizer, model = Optimisers.update(optimizer, model, grad)\n",
    "        if batch % 10 == 0\n",
    "            loss = loss_fn(model, X, y)\n",
    "            printfmtln(\"[Train] loss: {:.7f} [{:>3d}/{:>3d}]\", \n",
    "                loss, batch, num_batches)\n",
    "        end\n",
    "    end\n",
    "    model, optimizer\n",
    "end\n",
    "\n",
    "function test(loader, model, loss_fn)\n",
    "    num_batches = length(loader)\n",
    "    Flux.testmode!(model, true)\n",
    "    acc, tot = 0, 0\n",
    "    loss = 0f0\n",
    "    for (X, y) in loader\n",
    "        X, y = Flux.gpu(X), Flux.gpu(y)\n",
    "        pred = model(X)\n",
    "        acc += sum(Flux.onecold(pred) .== Flux.onecold(y))\n",
    "        tot += size(X)[end]\n",
    "        loss += loss_fn(model, X, y)\n",
    "    end\n",
    "    acc, avg_loss = acc / tot * 100, loss / num_batches\n",
    "    printfmtln(\"[Test] Accuracy: {:.1f}, Avg loss: {:.7f}\", \n",
    "        acc, avg_loss)\n",
    "    acc, avg_loss\n",
    "end\n",
    "\n",
    "init(rng) = Flux.glorot_uniform(rng)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct MyResnet\n",
    "    resnet\n",
    "    dense\n",
    "end\n",
    "function (a::MyResnet)(x)\n",
    "    x = a.resnet.layers[1](x)\n",
    "    x = Flux.AdaptiveMeanPool((1, 1))(x)\n",
    "    x = Flux.flatten(x)\n",
    "    a.dense(x)\n",
    "end\n",
    "Functors.@functor MyResnet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 및 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run_resnet (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function run_resnet(rng; pretrain)\n",
    "    sampler = get_image_sampler(\"cats_dogs\", rng)\n",
    "    resnet = Metalhead.ResNet(18, pretrain = pretrain)\n",
    "    model = MyResnet(resnet, Flux.Dense(512 => 2; init=init(rng))) \n",
    "    model = model |> Flux.gpu\n",
    "    optimizer = Optimisers.setup(Optimisers.Adam(), model)\n",
    "    loader = (sampler(10) for _ in 1:100) \n",
    "    loss_fn = (m, x, y) -> Flux.Losses.logitcrossentropy(m(x), y)\n",
    "    model, _ = train(loader, model, loss_fn, optimizer)\n",
    "    loader = (sampler(10) for _ in 1:20)\n",
    "    test(loader, model, loss_fn)\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사전 미 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss: 0.7123822 [ 10/100]\n",
      "[Train] loss: 0.5388184 [ 20/100]\n",
      "[Train] loss: 0.8376984 [ 30/100]\n",
      "[Train] loss: 0.6657692 [ 40/100]\n",
      "[Train] loss: 1.1854464 [ 50/100]\n",
      "[Train] loss: 0.6098708 [ 60/100]\n",
      "[Train] loss: 0.6977958 [ 70/100]\n",
      "[Train] loss: 0.6554491 [ 80/100]\n",
      "[Train] loss: 0.6035808 [ 90/100]\n",
      "[Train] loss: 0.8463958 [100/100]\n",
      "[Test] Accuracy: 50.0, Avg loss: 0.8647254\n"
     ]
    }
   ],
   "source": [
    "rng = MersenneTwister(1)\n",
    "run_resnet(rng; pretrain = false);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사전 학습 (전이 학습)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss: 0.6280646 [ 10/100]\n",
      "[Train] loss: 0.3220276 [ 20/100]\n",
      "[Train] loss: 0.2373100 [ 30/100]\n",
      "[Train] loss: 0.1000746 [ 40/100]\n",
      "[Train] loss: 0.2597194 [ 50/100]\n",
      "[Train] loss: 0.0759974 [ 60/100]\n",
      "[Train] loss: 0.0343409 [ 70/100]\n",
      "[Train] loss: 0.2529985 [ 80/100]\n",
      "[Train] loss: 0.3924147 [ 90/100]\n",
      "[Train] loss: 0.2217513 [100/100]\n",
      "[Test] Accuracy: 93.5, Avg loss: 0.1560094\n"
     ]
    }
   ],
   "source": [
    "Optimisers.trainable(x::MyResnet) = (; dense = x.dense)\n",
    "run_resnet(rng; pretrain = true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.0",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
