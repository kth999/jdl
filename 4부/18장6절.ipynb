{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18.6. 허깅페이스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 07:31:59.934875: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-22 07:32:00.176498: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-22 07:32:00.211215: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-22 07:32:00.211232: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-05-22 07:32:00.846450: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-22 07:32:00.846489: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-22 07:32:00.846492: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PyObject <module 'transformers' from '/home/tyfun/.local/lib/python3.10/site-packages/transformers/__init__.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using PyCall\n",
    "pytf = pyimport(\"transformers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이썬에 transformers 모듈이 설치되어 있지 않은 경우\n",
    "#@pyimport pip\n",
    "#pip.main([\"install\", \"transformers\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT base model (uncased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5-element Vector{Dict{Any, Any}}:\n",
       " Dict(\"score\" => 0.10731087625026703, \"token\" => 4827, \"token_str\" => \"fashion\", \"sequence\" => \"hello i'm a fashion model.\")\n",
       " Dict(\"score\" => 0.08774468302726746, \"token\" => 2535, \"token_str\" => \"role\", \"sequence\" => \"hello i'm a role model.\")\n",
       " Dict(\"score\" => 0.053383879363536835, \"token\" => 2047, \"token_str\" => \"new\", \"sequence\" => \"hello i'm a new model.\")\n",
       " Dict(\"score\" => 0.046672191470861435, \"token\" => 3565, \"token_str\" => \"super\", \"sequence\" => \"hello i'm a super model.\")\n",
       " Dict(\"score\" => 0.027095822617411613, \"token\" => 2986, \"token_str\" => \"fine\", \"sequence\" => \"hello i'm a fine model.\")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker = pytf.pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
    "unmasker(\"Hello I'm a [MASK] model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "768×5 adjoint(::Matrix{Float32}) with eltype Float32:\n",
       "  0.183457   -0.107541     -0.249168     0.0909832   -0.2782\n",
       " -0.416676    0.053653     -0.35873     -0.463723    -0.193687\n",
       " -0.308941   -0.0827718    -0.246794     0.139111     0.0527724\n",
       " -0.212909   -0.46497       0.143973     0.152972    -0.016622\n",
       " -0.472088   -0.031428     -0.318534    -0.220803     0.175561\n",
       " -0.395376   -0.460735     -0.483444    -0.600356    -0.760108\n",
       "  0.174218   -0.0703339    -0.205374     0.187732     0.00556535\n",
       "  0.363432    0.337521      0.511941     0.432029     0.29052\n",
       "  0.458574    0.382625      0.822231     0.175565     0.429204\n",
       " -0.236621   -0.0891502    -0.290467    -0.369064    -0.890835\n",
       "  0.163833    0.0246524     0.286978     0.294781     0.142459\n",
       " -0.12807     0.114612     -0.0676048    0.34227      0.311857\n",
       " -0.303468    0.129693      0.289223     0.147675     0.163047\n",
       "  ⋮                                                  \n",
       " -0.210652   -0.447384     -0.268612    -0.441203    -0.229407\n",
       " -0.426637   -0.507731     -0.805349    -0.940867    -0.676277\n",
       "  0.125773    0.014892      0.245671    -0.244719    -0.0384924\n",
       " -0.797983   -0.477678     -0.359532    -0.445047    -0.420487\n",
       " -0.293951   -0.000521873  -0.0718453    0.00862555   0.190004\n",
       " -0.614028   -0.397844     -0.285977    -0.441709    -0.556027\n",
       "  0.0472205  -0.501228     -0.285543    -0.130639    -0.776218\n",
       "  0.958017    0.966425      0.277634     0.654355     0.574352\n",
       " -0.184313   -0.138536     -0.374557    -0.339386    -0.203134\n",
       " -0.21432    -0.0426744     0.00201191  -0.367757    -0.211732\n",
       "  0.610833    0.307405      0.538092     0.749992     0.920329\n",
       "  0.33266     0.80202       0.435676     0.438166     0.0315099"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using CSV, DataFrames\n",
    "imdb = CSV.read(\"/home/tyfun/Downloads/IMDB Dataset.csv\", DataFrame);\n",
    "text = replace.(imdb.review, \"<br />\" => \" \")[1:5];\n",
    "tokenizer = pytf.BertTokenizer.from_pretrained(\"bert-base-uncased\");\n",
    "model = pytf.BertModel.from_pretrained(\"bert-base-uncased\");\n",
    "encoded_input = tokenizer(text, return_tensors=\"pt\", \n",
    "    padding=true, truncation=true);\n",
    "output = model(\n",
    "    input_ids = encoded_input.input_ids,\n",
    "    token_type_ids = encoded_input.token_type_ids,\n",
    "    attention_mask = encoded_input.attention_mask);\n",
    "features = output[\"last_hidden_state\"].detach().numpy()[:,1,:]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mtype OneHotArrays.OneHotArray{UInt32,1,2,Vector{UInt32}} does not exist in workspace; reconstructing\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ JLD2 ~/.julia/packages/JLD2/ryhNR/src/data/reconstructing_datatypes.jl:495\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "768×5 Matrix{Float32}:\n",
       "  0.184805   -0.103944     -0.248619     0.0923059   -0.275131\n",
       " -0.414875    0.0555436    -0.356611    -0.461243    -0.192297\n",
       " -0.306582   -0.0797797    -0.246718     0.138624     0.0530732\n",
       " -0.214175   -0.467376      0.144437     0.151393    -0.0189914\n",
       " -0.473402   -0.0332733    -0.317315    -0.222228     0.175625\n",
       " -0.397253   -0.463901     -0.485493    -0.602911    -0.761745\n",
       "  0.171968   -0.0710427    -0.208184     0.184724     0.00209193\n",
       "  0.360662    0.336918      0.511018     0.432924     0.287636\n",
       "  0.455813    0.381465      0.82192      0.175865     0.430091\n",
       " -0.237144   -0.0899128    -0.291191    -0.36698     -0.888839\n",
       "  0.166349    0.027981      0.286802     0.295981     0.14278\n",
       " -0.125876    0.113792     -0.0680187    0.343161     0.314132\n",
       " -0.303973    0.12852       0.28675      0.145333     0.163611\n",
       "  ⋮                                                  \n",
       " -0.211285   -0.446802     -0.26842     -0.441754    -0.225309\n",
       " -0.426631   -0.507301     -0.803833    -0.939892    -0.676997\n",
       "  0.12563     0.0131013     0.246624    -0.243433    -0.0378176\n",
       " -0.798742   -0.478167     -0.360631    -0.44573     -0.421797\n",
       " -0.294581   -0.000765582  -0.0721593    0.00860776   0.190046\n",
       " -0.614258   -0.400557     -0.285962    -0.442638    -0.556651\n",
       "  0.0452984  -0.500933     -0.286195    -0.129742    -0.7757\n",
       "  0.956586    0.965349      0.27688      0.653547     0.577773\n",
       " -0.181679   -0.137857     -0.37308     -0.340352    -0.202527\n",
       " -0.212163   -0.041558      0.00290451  -0.36518     -0.207437\n",
       "  0.610998    0.30813       0.535639     0.747009     0.919274\n",
       "  0.333653    0.80376       0.434525     0.440701     0.0337555"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import FileIO\n",
    "dic = FileIO.load(\"imdb_bert_feat.jld2\");\n",
    "feat_prev = dic[\"X\"][:,1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Float32}:\n",
       " 7.8082085f-6\n",
       " 4.351139f-6\n",
       " 4.2915344f-6\n",
       " 8.761883f-6\n",
       " 7.0929527f-6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Distances\n",
    "colwise(cosine_dist, feat_prev, features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5-element Vector{Dict{Any, Any}}:\n",
       " Dict(\"generated_text\" => \"I like to write julia code. The problem is that there are no Java interfaces to it, so that's why I need to do some more\")\n",
       " Dict(\"generated_text\" => \"I like to write julia code to help test and generate functions I've written before. The julia tools make it easy to create and use libraries\")\n",
       " Dict(\"generated_text\" => \"I like to write julia code.\\n\\nThe problem\\n\\nThe problem with Julia is that it doesn't have a single built-in\")\n",
       " Dict(\"generated_text\" => \"I like to write julia code for the Python code, just replace `cat` with `sudo pythonjulia`. I just tried using the Python\")\n",
       " Dict(\"generated_text\" => \"I like to write julia code where I'm not writing actual code.\\n\\nMy version of \\\"simple julia-ruby-server\\\" starts\")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pytf.pipeline(\"text-generation\", model=\"gpt2\")\n",
    "generator(\"I like to write julia code\", max_length=30, num_return_sequences=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <transformers.pipelines.text2text_generation.SummarizationPipeline object at 0x7f3d41233fa0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer = pytf.pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLE = \"\"\" \n",
    "At least 10 people were killed and 55 were injured in the southern Ukrainian city of Kherson after Russian shelling hit the area on Saturday, Yaroslav Yanushevych, head of the Kherson region military administration, said in a new update on the death toll.\n",
    "Yanushevych called on Kherson residents to donate blood to help save the lives of people injured in the shelling. \n",
    "He also said the Russians used \"Grad multiple-launch rocket systems to hit Kherson city center,\" and 18 people, among 55, are in critical condition at the moment. \n",
    "The head of the regional administration noted there were no children among the victims of Saturday morning's shelling.\n",
    "At the same time, he reported five people were killed and 17 were injured Friday as a result of Russian shelling.\n",
    "\"Among the injured is a six-year-old girl, doctors fought for her life and managed to save her,\" Yanushevych said. \"But, unfortunately, the six-year-old girl lost her eye and her ear. She has a broken leg. We will evacuate her to Kyiv.\" \n",
    "Yanushevych said the shelling of the city continued all day Saturday, especially the areas along the Dnipro river, and it prevented the rescuers from doing their job of clearing the rubble.\n",
    "The areas along the Dnipro river, such as Hydropark, Antonivka and Navtohavan have no heating or electricity. Yanushevych said people who live in these areas are under constant heavy shelling and \"need to immediately evacuate.\" \n",
    "\"It is almost impossible to restore the infrastructure in these areas,\" Yanushevych said.\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{Dict{Any, Any}}:\n",
       " Dict(\"summary_text\" => \"At least 10 people were killed and 55 were injured in the southern Ukrainian city of Kherson. 18 people, among 55, are in critical condition at the moment. The head of the regional administration noted no children among the victims.\")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(ARTICLE, max_length=130, min_length=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.0",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
